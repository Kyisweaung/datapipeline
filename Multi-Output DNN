# Fixed TFRecord + Transformer pipeline (Databricks)
# - configurable repeat for datasets (no infinite loops)
# - safer evaluation with steps limit
# - tf.data performance options
# - mixed precision kept, checkpointing added
# - small stylistic/robustness fixes

--------TRANSFORMERS technique--------------
-------------------------------------------------

import os
import time
import math
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input,
    Dense,
    LayerNormalization,
    Dropout,
    MultiHeadAttention,
    Add,
    Concatenate,
    Flatten,
    RepeatVector,
    TimeDistributed,
)
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from sklearn.metrics import mean_absolute_error, r2_score
import tensorflow.train as tftrain

# ---------------------------
# Config (tune these)
# ---------------------------
NUM_SHARDS = 256  # number of TFRecord files to create (shards)
TFRECORD_BASE = "/dbfs/tmp/liquidity_tfrecords_sharded"  # DBFS path (FUSE)
BATCH_SIZE = 1024  # try 512/1024 depending on memory
EPOCHS = 30
SHUFFLE_BUFFER = 50_000
USE_MIXED_PRECISION = True  # set False if you want pure float32
VERBOSE = 2
MODEL_CHECKPOINT_PATH = "/dbfs/tmp/liquidity_model_checkpoints/best_model.h5"

# ---------------------------
# Optional: enable mixed precision
# ---------------------------
if USE_MIXED_PRECISION:
    try:
        tf.keras.mixed_precision.set_global_policy("mixed_float16")
        print("Mixed precision enabled:", tf.keras.mixed_precision.global_policy().name)
    except Exception as e:
        print("Could not set mixed precision:", e)

# ---------------------------
# Start Spark and load table
# ---------------------------
spark = SparkSession.builder.getOrCreate()
table_name = "default.kpi_tmp_all_trans_liquidity_sub_base3_uu1_update5_consequence"
print("Loading table:", table_name)
df_spark = spark.table(table_name)

# cast decimals and strings (except msisdn) to double to avoid dtype issues
for c, t in df_spark.dtypes:
    if (t.startswith("decimal") or t == "string") and c != "msisdn":
        df_spark = df_spark.withColumn(c, col(c).cast("double"))

# ---------------------------
# Define columns (adjust range if you have fewer days)
# ---------------------------
TARGET_DAYS = 30
HIST_DAYS = 30

target_cols = [f"day{i}_bal" for i in range(1, TARGET_DAYS + 1)]
hist_cols = [f"hist_day{i}_bal" for i in range(1, HIST_DAYS + 1)]
# feature columns = all columns excluding target, hist, msisdn
all_cols = df_spark.columns
feature_cols = [c for c in all_cols if c not in target_cols + hist_cols + ["msisdn"]]

print(
    "Targets:",
    len(target_cols),
    "Historic timesteps:",
    len(hist_cols),
    "Static features:",
    len(feature_cols),
)

# ---------------------------
# Train / val split (Spark)
# ---------------------------
train_df = df_spark.sample(fraction=0.8, seed=42)
val_df = df_spark.subtract(train_df)
# cache counts once
train_count = train_df.count()
val_count = val_df.count()
print("Train rows (est):", train_count, "Val rows (est):", val_count)


# ---------------------------
# Helper: safely convert to float
# ---------------------------
def safe_float(val):
    try:
        if val is None or str(val).lower() in ["nan", "null"]:
            return 0.0
        return float(val)
    except:
        return 0.0


# ---------------------------
# Optimized TFRecord shard writer
# ---------------------------
def write_tfrecord_shards_optimized(
    spark_df,
    output_dir,
    hist_cols_local,
    feature_cols_local,
    target_cols_local,
    num_shards,
):
    import tensorflow as tf
    import os

    print(f"Writing TFRecord shards to {output_dir} with {num_shards} shards ...")

    cols_to_select = hist_cols_local + feature_cols_local + target_cols_local
    spark_sel = spark_df.select(*cols_to_select).repartition(num_shards)

    def partition_writer(partition_index, iterator):
        # Ensure output directory exists on each executor
        os.makedirs(output_dir, exist_ok=True)
        out_path = f"{output_dir}/part-{partition_index:05d}.tfrecord"
        writer = tf.io.TFRecordWriter(out_path)
        count = 0
        for row in iterator:
            values = [row[col] for col in cols_to_select]
            feature = {}
            for i, colname in enumerate(hist_cols_local):
                feature[f"hist_{i}"] = tf.train.Feature(
                    float_list=tf.train.FloatList(value=[safe_float(values[i])])
                )
            offset = len(hist_cols_local)
            for j, colname in enumerate(feature_cols_local):
                feature[f"feat_{j}"] = tf.train.Feature(
                    float_list=tf.train.FloatList(
                        value=[safe_float(values[offset + j])]
                    )
                )
            offset += len(feature_cols_local)
            for k, colname in enumerate(target_cols_local):
                feature[f"target_{k}"] = tf.train.Feature(
                    float_list=tf.train.FloatList(
                        value=[safe_float(values[offset + k])]
                    )
                )
            example = tf.train.Example(features=tf.train.Features(feature=feature))
            writer.write(example.SerializeToString())
            count += 1
        writer.close()
        return [f"WROTE {out_path} rows={count}"]

    logs = spark_sel.rdd.mapPartitionsWithIndex(
        lambda idx, it: partition_writer(idx, it)
    ).collect()
    # print up to first 10 partition logs (if many)
    for line in logs[:10]:
        print(line)
    print("Finished writing TFRecord shards.")


# run writing (this might take some minutes depending on your cluster I/O)
if not os.path.exists(TFRECORD_BASE) or len(os.listdir(TFRECORD_BASE)) < NUM_SHARDS:
    try:
        dbutils.fs.rm("dbfs:/tmp/liquidity_tfrecords_sharded", recurse=True)
    except Exception:
        pass
    write_tfrecord_shards_optimized(
        train_df,
        TFRECORD_BASE + "/train",
        hist_cols,
        feature_cols,
        target_cols,
        NUM_SHARDS,
    )
    write_tfrecord_shards_optimized(
        val_df,
        TFRECORD_BASE + "/val",
        hist_cols,
        feature_cols,
        target_cols,
        max(16, NUM_SHARDS // 16),
    )
else:
    print("TFRecord dir exists and appears sharded — skipping write.")


# ---------------------------
# TFRecord parsing & dataset creation (fast pipeline)
# ---------------------------
def parse_example_serialized(serialized_example):
    # build feature description dict (FixedLenFeature of shape [1])
    feature_description = {}
    for i in range(len(hist_cols)):
        feature_description[f"hist_{i}"] = tf.io.FixedLenFeature([1], tf.float32)
    for i in range(len(feature_cols)):
        feature_description[f"feat_{i}"] = tf.io.FixedLenFeature([1], tf.float32)
    for i in range(len(target_cols)):
        feature_description[f"target_{i}"] = tf.io.FixedLenFeature([1], tf.float32)
    parsed = tf.io.parse_single_example(serialized_example, feature_description)
    X_hist = tf.stack(
        [parsed[f"hist_{i}"] for i in range(len(hist_cols))], axis=0
    )  # (hist_len, 1)
    X_static = tf.stack(
        [parsed[f"feat_{i}"] for i in range(len(feature_cols))], axis=0
    )  # (n_features, 1)
    y = tf.stack(
        [parsed[f"target_{i}"] for i in range(len(target_cols))], axis=0
    )  # (target_len, 1)
    # shapes: make X_hist shape=(hist_len,1), X_static (n_features,), y (target_len,)
    X_hist = tf.reshape(X_hist, (len(hist_cols), 1))
    X_static = tf.reshape(X_static, (len(feature_cols),))
    y = tf.reshape(y, (len(target_cols),))
    return {"hist_input": X_hist, "static_input": X_static}, tf.expand_dims(y, -1)


def make_dataset_from_tfrecord_dir(
    tfrecord_dir_glob,
    batch_size=BATCH_SIZE,
    shuffle=True,
    repeat=True,
    shuffle_buffer=SHUFFLE_BUFFER,
):
    files = tf.io.gfile.glob(tfrecord_dir_glob)
    if len(files) == 0:
        raise RuntimeError(f"No TFRecord files found for pattern: {tfrecord_dir_glob}")
    print(f"Found {len(files)} TFRecord files (example): {files[:3]}")

    ds = tf.data.Dataset.list_files(tfrecord_dir_glob, shuffle=shuffle)
    # read files in parallel
    ds = ds.interleave(lambda f: tf.data.TFRecordDataset(f),
                       cycle_length=tf.data.AUTOTUNE,
                       num_parallel_calls=tf.data.AUTOTUNE,
                       deterministic=False)
    # parse
    ds = ds.map(parse_example_serialized, num_parallel_calls=tf.data.AUTOTUNE)

    if shuffle:
        ds = ds.shuffle(shuffle_buffer)

    # repeat only when requested (training should repeat; validation usually not)
    if repeat:
        ds = ds.repeat()

    # batch: drop_remainder True for training repeated datasets, False for validation/one-shot
    drop_remainder = repeat  # True for training, False for validation
    ds = ds.batch(batch_size, drop_remainder=drop_remainder)

    # speed options
    options = tf.data.Options()
    options.experimental_deterministic = False
    options.threading.private_threadpool_size = 48
    ds = ds.with_options(options)

    ds = ds.prefetch(tf.data.AUTOTUNE)
    return ds


train_pattern = TFRECORD_BASE + "/train/*.tfrecord"
val_pattern = TFRECORD_BASE + "/val/*.tfrecord"

print("Creating tf.data datasets (train/val)...")
train_ds = make_dataset_from_tfrecord_dir(
    train_pattern, batch_size=BATCH_SIZE, shuffle=True, repeat=True
)
val_ds = make_dataset_from_tfrecord_dir(
    val_pattern, batch_size=BATCH_SIZE, shuffle=False, repeat=False
)

# quick sanity: iterate 1 batch to see pipeline works and prints shapes
print("Sampling one batch to validate pipeline (this will materialize one batch)...")
for batch_x, batch_y in train_ds.take(1):
    print("Batch X_hist shape:", batch_x["hist_input"].shape)
    print("Batch X_static shape:", batch_x["static_input"].shape)
    print("Batch y shape:", batch_y.shape)
    break

# ---------------------------
# Build Transformer model inside strategy scope
# ---------------------------
strategy = tf.distribute.MirroredStrategy()
print("Number of devices:", strategy.num_replicas_in_sync)
with strategy.scope():
    # simple transformer encoder block
    def transformer_encoder(inputs, head_size=64, num_heads=4, ff_dim=128, dropout=0.1):
        x = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs)
        x = Dropout(dropout)(x)
        x = Add()([x, inputs])
        x = LayerNormalization(epsilon=1e-6)(x)
        x_ff = Dense(ff_dim, activation="relu")(x)
        x_ff = Dense(int(inputs.shape[-1]))(x_ff)
        x_ff = Dropout(dropout)(x_ff)
        x = Add()([x, x_ff])
        x = LayerNormalization(epsilon=1e-6)(x)
        return x

    hist_input = Input(shape=(len(hist_cols), 1), name="hist_input")
    x = Dense(64, activation="relu")(hist_input)
    x = transformer_encoder(x, head_size=32, num_heads=2, ff_dim=64, dropout=0.1)
    x = transformer_encoder(x, head_size=32, num_heads=2, ff_dim=64, dropout=0.1)
    x = Flatten()(x)

    static_input = Input(shape=(len(feature_cols),), name="static_input")
    static_dense = Dense(64, activation="relu")(static_input)

    concat = Concatenate()([x, static_dense])
    concat = RepeatVector(len(target_cols))(concat)
    decoder = transformer_encoder(
        concat, head_size=32, num_heads=2, ff_dim=64, dropout=0.1
    )
    # final layer must be float32 to avoid returning float16 in mixed precision
    output = TimeDistributed(Dense(1, activation="linear", dtype="float32"))(decoder)

    model = Model(inputs=[hist_input, static_input], outputs=output)
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss="mae")
    model.summary()

# ---------------------------
# Callbacks and training
# ---------------------------
# compute steps per epoch using cached counts
steps_per_epoch = math.ceil(train_count / BATCH_SIZE)
validation_steps = math.ceil(val_count / BATCH_SIZE)

early_stop = EarlyStopping(monitor="val_loss", patience=8, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=4, min_lr=1e-6)
os.makedirs(os.path.dirname(MODEL_CHECKPOINT_PATH), exist_ok=True)
checkpoint = ModelCheckpoint(
    MODEL_CHECKPOINT_PATH, monitor="val_loss", save_best_only=True, save_weights_only=False
)

print(f"START TRAINING: steps_per_epoch={steps_per_epoch}, validation_steps={validation_steps}")
t0 = time.time()

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=[early_stop, reduce_lr, checkpoint],
    verbose=VERBOSE,
)

t1 = time.time()
print(f"Training finished in {(t1 - t0)/60:.2f} minutes")

# ---------------------------
# Batch-wise evaluation on val_ds (safe bounded)
# ---------------------------
def predict_from_dataset(dataset, model, steps=None):
    """
    Predict on a dataset. If dataset is repeating (infinite), steps must be provided.
    If dataset is finite, steps may be None and function will iterate until exhaustion.
    Returns (y_all, p_all) stacked arrays.
    """
    ys = []
    preds = []
    i = 0
    if steps is None:
        # try to iterate until dataset is exhausted
        for batch_x, batch_y in dataset:
            pred = model.predict(batch_x, verbose=0)
            ys.append(batch_y.numpy())
            preds.append(pred)
            i += 1
            if i % 10 == 0:
                print(f"Predicted {i} batches...")
    else:
        # iterate exactly `steps` batches
        it = iter(dataset)
        for _ in range(steps):
            try:
                batch_x, batch_y = next(it)
            except StopIteration:
                break
            pred = model.predict(batch_x, verbose=0)
            ys.append(batch_y.numpy())
            preds.append(pred)
            i += 1
            if i % 10 == 0:
                print(f"Predicted {i} batches...")
    if len(ys) == 0:
        return np.empty((0,)), np.empty((0,))
    y_all = np.vstack(ys)
    p_all = np.vstack(preds)
    return y_all, p_all


print("Running batch-wise evaluation on validation set...")
# val_ds is non-repeating, but we still limit by validation_steps just in case
y_true, y_pred = predict_from_dataset(val_ds, model, steps=validation_steps)
y_true_flat = y_true.squeeze(-1)
y_pred_flat = y_pred.squeeze(-1)

overall_mae = mean_absolute_error(y_true_flat, y_pred_flat)
overall_r2 = r2_score(y_true_flat, y_pred_flat, multioutput="uniform_average")
print(f"\nOverall MAE: {overall_mae:,.2f}")
print(f"Overall R²: {overall_r2:.4f}")

print("\nPer-day MAE / R²:")
for i, col in enumerate(target_cols):
    mae_i = mean_absolute_error(y_true_flat[:, i], y_pred_flat[:, i])
    r2_i = r2_score(y_true_flat[:, i], y_pred_flat[:, i])
    print(f"{col:<10}  MAE: {mae_i:,.2f}  R²: {r2_i:.4f}")

print("\n✅ Pipeline finished. Best model saved to:", MODEL_CHECKPOINT_PATH)
